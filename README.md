# DeepReinforcementLearning

## Code for the book 
 - Deep Reinforcement Learning - Frontiers of Artificial Intelligence
                                                        - By Mohit Sewak
https://www.springer.com/gp/book/9789811382840


# How to Cite
If you use the code in any of your publications, please cite the book and the relevant chapters as below (BibTex):

## Entire Book:

@book{sewak2019deep,
  title={Deep Reinforcement Learning},
  author={Sewak, Mohit},
  year={2019},
  publisher={Springer}
}

## Individual Chapters

### Introduction to Reinforcement Learning:

@incollection{sewak2019introduction,
  title={Introduction to Reinforcement Learning},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={1--18},
  year={2019},
  publisher={Springer}
}


### Coding the (RL) Environment and the MDP Solution:

@incollection{sewak2019coding,
  title={Coding the Environment and MDP Solution},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={29--49},
  year={2019},
  publisher={Springer}
}


### Mathematical and Algorithmic Understanding of Reinforcement Learning:

@incollection{sewak2019mathematical,
  title={Mathematical and Algorithmic Understanding of Reinforcement Learning},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={19--27},
  year={2019},
  publisher={Springer}
}


### Temporal Difference Learning, SARSA, and Q-Learning:

@incollection{sewak2019temporal,
  title={Temporal Difference Learning, SARSA, and Q-Learning},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={51--63},
  year={2019},
  publisher={Springer}
}


### Q-Learning in Code:

@incollection{sewak2019q,
  title={Q-Learning in Code},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={65--74},
  year={2019},
  publisher={Springer}
}


### DQN, Double DQN, Dueling DQN:

@incollection{sewak2019deep,
  title={Deep Q Network (DQN), Double DQN, and Dueling DQN},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={95--108},
  year={2019},
  publisher={Springer}
}


### Double DQN in Code:

@incollection{sewak2019double,
  title={Double DQN in Code},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={109--126},
  year={2019},
  publisher={Springer}
}


### Policy-Based Reinforcement Learning Approaches:

@incollection{sewak2019policy,
  title={Policy-Based Reinforcement Learning Approaches},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={127--140},
  year={2019},
  publisher={Springer}
}


### Deterministic Policy Gradient and the DDPG:

@incollection{sewak2019deterministic,
  title={Deterministic Policy Gradient and the DDPG},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={173--184},
  year={2019},
  publisher={Springer}
}


### Deep Deterministic Policy Gradient (DDPG) in Code:

@incollection{sewak2019ddpg,
  title={DDPG in Code},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={185--191},
  year={2019},
  publisher={Springer}
}

### Aynchronous Actor Critic (A3C)

@incollection{sewak2019actor,
  title={Actor-Critic Models and the A3C},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={141--152},
  year={2019},
  publisher={Springer}
}

### Aynchronous Actor Critic (A3C) in Code:

@incollection{sewak2019a3c,
  title={A3C in Code},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={153--172},
  year={2019},
  publisher={Springer}
}


### (Reinforcement Learning) Implementation Resources:

@incollection{sewak2019implementation,
  title={Implementation Resources},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={89--94},
  year={2019},
  publisher={Springer}
}

### Introduction to Deep Learning:

@incollection{sewak2019introduction,
  title={Introduction to Deep Learning},
  author={Sewak, Mohit},
  booktitle={Deep Reinforcement Learning},
  pages={75--88},
  year={2019},
  publisher={Springer}
}

